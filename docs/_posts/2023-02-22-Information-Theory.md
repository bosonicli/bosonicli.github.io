---
title: 2023-02-22 - Information Theory
date: 2023-02-22
author: bosonicli
tags:
-   Ether
---

[toc]

# Entropy

Shannon Entropy

$$
\begin{aligned}
    H (X) & \equiv - \Sigma_{ x \in \mathcal{X} } p(x) log(p(x))
\end{aligned}
$$

Renyi Entropy

$$
\begin{aligned}
    H^{\alpha} (X) & \equiv \frac{1}{1-\alpha} log( \Sigma_{i} p_{i}^{\alpha})    \\
    \lim_{ \alpha \rightarrow 1 } &= H (X)
\end{aligned}
$$

Von-Neumann Entropy

$$
\begin{aligned}
    S & \equiv - tr( \rho ln(\rho) )
\end{aligned}
$$

# Encode

# Problems remain

+   Digital signal

    Sampling Theory
    
    frequency encoding limit
